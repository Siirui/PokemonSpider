<div class="cover" style="page-break-after:always;font-family:方正公文仿宋;width:100%;height:100%;border:none;margin: 0 auto;text-align:center;">
    <div style="width:60%;margin: 0 auto;height:0;padding-bottom:10%;">
        </br>
        <img src="/Users/siri/Desktop/Templates/typora-论文模版/校名.jpg" alt="校名" style="width:100%;"/>
    </div>
    </br></br></br></br></br>
    <div style="width:60%;margin: 0 auto;height:0;padding-bottom:40%;">
        <img src="/Users/siri/Desktop/Templates/typora-论文模版/校徽.jpg" alt="校徽" style="width:100%;"/>
	</div>
    </br></br></br></br></br></br></br></br>
    <span style="font-family:华文黑体Bold;text-align:center;font-size:20pt;margin: 10pt auto;line-height:30pt;">基于Google Teachable Machine实现精灵宝可梦属性识别</span>
    </br>
    </br>
    <table style="border:none;text-align:center;width:72%;font-family:仿宋;font-size:14px; margin: 0 auto;">
    	<tr style="font-weight:normal;"> 
    		<td style="width:20%;text-align:right;">上课时间</td>
    		<td style="width:2%">：</td> 
    		<td style="width:40%;font-weight:normal;border-bottom: 1px solid;text-align:center;font-family:华文仿宋"> 周四3、4节</td>     </tr>
    	<tr style="font-weight:normal;"> 
    		<td style="width:20%;text-align:right;">授课教师</td>
    		<td style="width:2%">：</td> 
    		<td style="width:40%;font-weight:normal;border-bottom: 1px solid;text-align:center;font-family:华文仿宋">赵才荣 </td>     </tr>
    	<tr style="font-weight:normal;"> 
    		<td style="width:20%;text-align:right;">姓　　名</td>
    		<td style="width:2%">：</td> 
    		<td style="width:40%;font-weight:normal;border-bottom: 1px solid;text-align:center;font-family:华文仿宋"> 孙睿</td>     </tr>
    	<tr style="font-weight:normal;"> 
    		<td style="width:20%;text-align:right;">学　　号</td>
    		<td style="width:2%">：</td> 
    		<td style="width:40%;font-weight:normal;border-bottom: 1px solid;text-align:center;font-family:华文仿宋">2054087 </td>     </tr>
    	<tr style="font-weight:normal;"> 
    		<td style="width:20%;text-align:right;">日　　期</td>
    		<td style="width:2%">：</td> 
    		<td style="width:40%;font-weight:normal;border-bottom: 1px solid;text-align:center;font-family:华文仿宋">2022/03/25</td>     </tr>
    </tbody>              
    </table>
</div>




<!-- 注释语句：导出PDF时会在这里分页 -->

## 实现背景

2022年1月28日宝可梦最新作《宝可梦传说：阿尔宙斯》发布，其中包含了一些新的宝可梦还有以前宝可梦的变化体。作为玩家，判断一个宝可梦的属性是一件非常重要的事情，这决定了玩家对该宝可梦的攻击技能和应战宝可梦。然而判断宝可梦的属性不是一件容易的事，宝可梦共有18种属性，分别为**一般，飞行，火，超能力，水，虫，电，岩石，草，幽灵，冰，龙，格斗，恶，毒，钢，地面和妖精**，其中许多宝可梦同时具有2个属性，因此对其属性的判断是模糊困难的。本次笔者就想尝试使用Teachable Machine实现宝可梦属性的分类。

## 数据获取

本次笔者使用的数据来源有两个：

1. kaggle上宝可梦的数据集：https://www.kaggle.com/datasets/vishalsubbiah/pokemon-images-and-types该数据集收集了第一世代到第七世代的所有宝可梦。

   但是由于该数据集是将图片放在一个文件夹下，并不方便提交到Teachable Machine上，因此写了个脚本将其按属性分类

   ```python
   import os, sys
   import re
   import shutil
   
   re_han = re.compile("([\u4E00-\u9FD5a-zA-Z0-9+#&\._%\-]+)", re.U)
   re_skip = re.compile("(\r\n|\s)", re.U)
   
   type_dict={}
   def fetch_type(filename):
       with open(os.path.join(os.getcwd(), filename), mode="r+", encoding="utf-8") as r:
           lines = r.readlines()
       for i in range (1, len(lines)):
           blocks = re_han.split(lines[i])
           name = ""
           types = []
           for blk in blocks:
               if not blk:
                   continue
               if re_han.match(blk):
                   if name == "":
                       name = blk
                   else:
                       types.append(blk)
           
           for type_ in types:
               type_dict.setdefault(type_,[]).append(name)
   
   def sort_data(src_path, dst_path):
       for type_ in type_dict:
           type_dir_path = dst_path + str(type_)
           if not os.path.exists(type_dir_path):
               os.system("mkdir " + type_dir_path)
           for pokemon in type_dict[type_]:
               pokemon_image_path = src_path + str(pokemon) + ".png"
               if not os.path.exists(pokemon_image_path):
                   pokemon_image_path = src_path + str(pokemon) + ".jpg"
               if os.path.exists(pokemon_image_path):
               # print(pokemon_image_path)
               # print(os.path.exists(pokemon_image_path))
                   shutil.copyfile(pokemon_image_path, type_dir_path + "/" + str(pokemon) + "-spider.png")
           
   
   fetch_type("pokemon.csv")
   # for type_ in type_dict:
   #     print(str(type_) + ":\n" + str(type_dict[type_]))
   sort_data("./images/image/", "./sorted_images/")
   #shutil.copyfile("./images/images/abomasnow.png", "./sorted_images/Bug/abomasnow.png")
   ```

   经过分类后，笔者将分类好的图片提交到TeachabelMachine上，但是训练后的效果不好。经分析有两个可能原因：一是数据的分布不均匀，由于宝可梦每个属性的数量差距较大，比如水属性有100+，而第六世代引入的妖精属性数据仅有30+；第二单个标签下的样本数较小，训练效果不好。考虑到上述两个原因，笔者额外收集了另一些数据。

2. wiki.52poke.com上宝可梦的图片，笔者通过自己爬虫将神奇宝贝百科上第一时代到第八时代的所有宝可梦主页的图片爬虫下来，并进行分类。注意到kaggle数据的图片质量较低，分辨率小，而百科上的图片较大。而同一宝可梦的图片里的姿态不同，因此可以扩充数据量。爬虫代码如下。

   ```python
   from bs4 import BeautifulSoup
   import urllib3
   import os
   import re
   import requests
   
   urllib3.disable_warnings()
   
   class PokemonSpider(object):
       def __init__(self):
           self.index = "https://wiki.52poke.com/wiki/%E5%AE%9D%E5%8F%AF%E6%A2%A6%E5%88%97%E8%A1%A8%EF%BC%88%E6%8C%89%E5%85%A8%E5%9B%BD%E5%9B%BE%E9%89%B4%E7%BC%96%E5%8F%B7%EF%BC%89/%E7%AE%80%E5%8D%95%E7%89%88"
           self.root = "https://wiki.52poke.com{}"
           self.headers = {'User-Agent': 'Mozilla/4.0'}
           self.pokemon_url=[]
   
       def get_pokemon_url(self):
           res = requests.get(url=self.index, verify=False)
           res.encoding = "utf-8"
           html_index = res.text
           soup = BeautifulSoup(html_index, "html.parser")
           pokemon_list = soup.findAll(name="a", attrs={"href": re.compile('^/wiki/[A-Za-z0-9]*?$'), "class": re.compile('mw-redirect')})
           for pokemon in pokemon_list:
               pokemon = str(pokemon)
               pattern = re.compile(r'href="(/wiki/[A-Za-z0-9]*?)"')
               self.pokemon_url.append(pattern.findall(pokemon))
   
       def get_pokemon_imgae(self, url):
           res = requests.get(url=url, verify=False)
           res.encoding = "utf-8"
           html = res.text
           soup = BeautifulSoup(html)
           image = soup.find(name='img', attrs={"width": '300'})
           # print(image)
           if image is None:
               image = soup.find('img', width='120')
           image_address = image.get('data-url')
           image_url = "https://s1.52poke.wiki{}".format(image_address[18:])
           return image_url
   
       def save_image(self, url, name):
           root = "./image"
           path = str(root) + "/" + str(name) + ".png"
           if not os.path.exists(root):
               os.mkdir(root)
           if not os.path.exists(path):
               requests.packages.urllib3.disable_warnings()
               res = requests.get(url=url, verify=False)
               with open(path, 'wb') as f:
                   f.write(res.content)
   
       def run(self):
           self.get_pokemon_url()
           for sub_url in self.pokemon_url:
               if sub_url[0] == "/wiki/Pmlists":
                   continue
               pokemon_url = self.root.format(sub_url[0])
               pokemon_name = sub_url[0][6:]
               image_url = self.get_pokemon_imgae(pokemon_url)
               self.save_image(image_url, pokemon_name);
               # break
               # print(pokemon_url)
   
   spider = PokemonSpider()
   spider.run()
   ```

   

## 模型训练

将宝可梦的图片上传到Teachable Machine进行分类，训练效果不佳。根据2.1中笔者分析，由于每种宝可梦数量差距较大，最终笔者筛选了数据总数在150以上的属性，最后只进行**虫，火，飞行，草，一般，水，超能力**这7个属性的识别。模型训练后，笔者将模型导入到本地，并使用《宝可梦传说：阿尔宙斯》中新形态的宝可梦进行测试，测试精度较之前的尝试有所提高，但是精度仍然不高，代码见下。

```python
```

## Fashion-MNIST 图像分类识别实现

在Teachable Machine实现之外，笔者尝试了使用pytorch实现了Fashion-MNIST图像分类识别。由于对卷积网络的认识还较浅，本次使用的是两个全连接层来实现神经网络。进行5轮epochs训练，最后的loss和accuracy为

`epoch 5, loss 0.0014, train acc 0.865, test acc 0.805`

具体代码见下：

```python
import torch
from torch import nn
from torch.nn import init
import numpy as np
import sys
sys.path.append("..")
from d2l_pytorch import d2l_pytorch as d2l

num_inputs, num_outputs, num_hiddens = 784, 10, 256

net = nn.Sequential(
    d2l.FlattenLayer(),
    nn.Linear(num_inputs, num_hiddens),
    nn.ReLU(),
    nn.Linear(num_hiddens, num_outputs)
)

init.normal_(net[1].weight, mean=0, std=0.01)
init.constant_(net[1].bias, val=0)
batch_size = 256
train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)
loss = torch.nn.CrossEntropyLoss()

optimizer = torch.optim.SGD(net.parameters(), lr=0.5)

num_epochs = 5
d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, None, None, optimizer)

X, y = iter(test_iter).next()
true_labels = d2l.get_fashion_mnist_labels(y.numpy())
pred_labels = d2l.get_fashion_mnist_labels(net(X).argmax(dim=1))
titles = [true + '\n' + pred for true, pred in zip(true_labels, pred_labels)]
d2l.show_fashion_mnist(X[0:9], titles[0:9])

```

其中`d2l_pytorch`这个包为学习时不断构筑的工具集，见下：

```pytorch
import torch
from IPython import display
from matplotlib import pyplot as plt
import numpy as np
from matplotlib_inline import backend_inline as bi
import random
import torchvision
import torchvision.transforms as transforms
import torch.nn as nn
import sys
import time


def linreg(X, w, b):
    return torch.mm(X, w) + b


def use_svg_display():
    # display with svg
    bi.set_matplotlib_formats('svg')


def set_figsize(figsize=(3.5, 2.5)):
    use_svg_display()
    plt.rcParams['figure.figsize'] = figsize


def data_iter(batch_size, features, labels):
    num_examples = len(features)
    indices = list(range(num_examples))
    random.shuffle(indices)
    for i in range(0, num_examples, batch_size):
        j = torch.LongTensor(indices[i: min(i + batch_size, num_examples)])
        yield features.index_select(0, j), labels.index_select(0, j)


def squared_loss(y_hat, y):
    return (y_hat - y.view(y_hat.size())) ** 2 / 2


def sgd(params, lr, batch_size):
    for param in params:
        param.data -= lr * param.grad / batch_size


def get_fashion_mnist_labels(labels):
    text_labels = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat',
                   'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']
    return [text_labels[int(i)] for i in labels]


def show_fashion_mnist(images, labels):
    use_svg_display()
    _, figs = plt.subplots(1, len(images), figsize=(12,12))
    for f, img, lbl in zip(figs, images, labels):
        f.imshow(img.view((28, 28)).numpy())
        f.set_title(lbl)
        f.axes.get_xaxis().set_visible(False)
        f.axes.get_yaxis().set_visible(False)
    plt.show()


def evaluate_accuracy(data_iter, net):
    acc_sum, n = 0.0, 0
    for X, y in data_iter:
        if isinstance(net, torch.nn.Module):
            net.eval()
            acc_sum += (net(X).argmax(dim=1) == y).float().sum().item()
            net.train()
        else:
            if ('is_training' in net.__code__.co_varnames):
                acc_sum += (net(X, is_training=False).argmax(dim=1) == y).float().sum().item()
            else:
                acc_sum += (net(X).argmax(dim=1) == y).float().sum().item()
        n += y.shape[0]
    return acc_sum / n


def train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, params=None, lr=None, optimizer=None):
    for epoch in range(num_epochs):
        train_l_sum, train_acc_sum, n = 0.0, 0.0, 0
        for X, y in train_iter:
            y_hat = net(X)
            l = loss(y_hat, y).sum()

            # set gradient to zero
            if optimizer is not None:
                optimizer.zero_grad()
            elif params is not None and params[0].grad is not None:
                for param in params:
                    param.grad.data.zero_()

            l.backward()
            if optimizer is None:
                sgd(params, lr, batch_size)
            else:
                optimizer.step()

            train_l_sum += l.item()
            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().item()
            n += y.shape[0]
        test_acc = evaluate_accuracy(test_iter, net)
        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f' % (epoch + 1, train_l_sum/n, train_acc_sum/n, test_acc))


class FlattenLayer(nn.Module):
    def __init__(self):
        super(FlattenLayer, self).__init__()
    def forward(self, x):
        return x.view(x.shape[0], -1)


def load_data_fashion_mnist(batch_size):
    if sys.platform.startswith('win'):
        num_workers = 0
    else:
        num_workers = 0
    mnist_train = torchvision.datasets.FashionMNIST(root='~/Datasets/FashionMNIST', train=True, download=True, transform=transforms.ToTensor())
    mnist_test = torchvision.datasets.FashionMNIST(root='~/Datasets/FashionMNIST', train=False, download=True, transform=transforms.ToTensor())
    train_iter = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle = True, num_workers=num_workers)
    test_iter = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle = False, num_workers=num_workers)
    return train_iter, test_iter


def semilogy(x_vals, y_vals, x_label, y_label, x2_vals=None, y2_vals=None, legend=None, figsize=(3.5, 2.5)):
    set_figsize(figsize)
    plt.xlabel(x_label)
    plt.ylabel(y_label)
    plt.semilogy(x_vals, y_vals)
    if x2_vals and y2_vals:
        plt.semilogy(x2_vals, y2_vals, linestyle=":")
        plt.legend(legend)
    plt.show()


class Timer:
    def __init__(self):
        self.times = []
        self.start()

    def start(self):
        self.tik = time.time()

    def stop(self):
        self.times.append(time.time() - self.tik)
        return self.times[-1]

    def avg(self):
        return sum(self.times) / len(self.times)

    def sum(self):
        return sum(self.times)

    def cumsum(self):
        return np.array(self.times).cumsum().tolist()

```

